<!DOCTYPE html>
<html>
<head>
  <title>Image Recognition with Camera</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.9.0/dist/tf.min.js"></script>
  <style>
    #video {
      width: 100%;
      height: auto;
      transform: scaleX(-1);
    }

    #canvas {
      display: none;
    }

    #camera-button {
      display: block;
      margin: 20px auto;
      padding: 10px 20px;
      font-size: 16px;
    }
  </style>
</head>
<body>
  <h1>Image Recognition with Camera</h1>
  <button id="camera-button">Enable Camera</button>
  <video id="video" playsinline></video>
  <canvas id="canvas"></canvas>

  <script>
    const videoElement = document.getElementById('video');
    const canvasElement = document.getElementById('canvas');
    const cameraButton = document.getElementById('camera-button');

    let model;
    let stream;
    let videoWidth, videoHeight;

    async function enableCamera() {
      try {
        stream = await navigator.mediaDevices.getUserMedia({ video: true });
        videoElement.srcObject = stream;
        await videoElement.play();
        videoWidth = videoElement.videoWidth;
        videoHeight = videoElement.videoHeight;
        cameraButton.disabled = true;

        await loadModel();
        classifyFrame();
      } catch (error) {
        console.error('Error accessing the camera:', error);
      }
    }

    async function loadModel() {
      model = await tf.loadLayersModel('model.json');
    }

    async function classifyFrame() {
      const context = canvasElement.getContext('2d');
      context.drawImage(videoElement, 0, 0, videoWidth, videoHeight);
      const image = tf.browser.fromPixels(canvasElement);
      const predictions = await model.predict(image);
      console.log('Predictions:', predictions);

      // Perform further processing or display predictions in the UI

      requestAnimationFrame(classifyFrame);
    }

    cameraButton.addEventListener('click', enableCamera);
  </script>
</body>
</html>
