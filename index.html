<!DOCTYPE html>
<html>
<head>
  <title>Image Recognition with Camera</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.9.0/dist/tf.min.js"></script>
  <style>
    #video {
      width: 100%;
      max-width: 640px; /* Максимальная ширина видео */
      height: auto;
      transform: scaleX(-1);
    }

    #canvas {
      display: none;
    }

    #camera-button {
      display: block;
      margin: 20px auto;
      padding: 10px 20px;
      font-size: 16px;
    }

    #capture-button {
      display: block;
      margin: 20px auto;
      padding: 10px 20px;
      font-size: 16px;
    }

    #prediction-text {
      font-size: 24px;
      font-weight: bold;
      text-align: center;
      margin-top: 20px;
    }
  </style>
</head>
<body>
  <h1>Image Recognition with Camera</h1>
  <button id="camera-button">Enable Camera</button>
  <button id="capture-button" disabled>Capture Image</button>
  <video id="video" playsinline></video>
  <canvas id="canvas"></canvas>
  <div id="prediction-text"></div>

  <script>
    const videoElement = document.getElementById('video');
    const canvasElement = document.getElementById('canvas');
    const cameraButton = document.getElementById('camera-button');
    const captureButton = document.getElementById('capture-button');
    const predictionText = document.getElementById('prediction-text');

    // Добавляем названия классов
    const classes = ['class1', 'class2', 'class3'];

    let model;
    let stream;
    let videoWidth, videoHeight;
    let captureImage = false;

    async function enableCamera() {
      try {
        stream = await navigator.mediaDevices.getUserMedia({ video: true });
        videoElement.srcObject = stream;
        await videoElement.play();
        videoWidth = videoElement.videoWidth;
        videoHeight = videoElement.videoHeight;
        cameraButton.disabled = true;
        captureButton.disabled = false;

        await loadModel();
        classifyFrame();
      } catch (error) {
        console.error('Error accessing the camera:', error);
      }
    }

    async function loadModel() {
      model = await tf.loadLayersModel('model.json');
    }

    function captureAndClassifyImage() {
      captureImage = true;
    }

    async function classifyFrame() {
      const context = canvasElement.getContext('2d');

      // Задаем размеры canvas, соответствующие размерам видео
      canvasElement.width = videoWidth;
      canvasElement.height = videoHeight;

      context.drawImage(videoElement, 0, 0, videoWidth, videoHeight, 0, 0, canvasElement.width, canvasElement.height);

      if (captureImage) {
        captureImage = false;

        const image = tf.browser.fromPixels(canvasElement);
        const resizedImage = tf.image.resizeBilinear(image, [model.inputs[0].shape[1], model.inputs[0].shape[2]]);
        const processedImage = resizedImage.expandDims();
        const predictions = await model.predict(processedImage).data();

        console.log('Predictions:', predictions);

        const maxPredictionIndex = predictions.indexOf(Math.max(...predictions));

        // Выводим только название класса на экран
        predictionText.textContent = `Predicted class: ${classes[maxPredictionIndex]}`;
      }

      requestAnimationFrame(classifyFrame);
    }

    cameraButton.addEventListener('click', enableCamera);
    captureButton.addEventListener('click', captureAndClassifyImage);
  </script>
</body>
</html>
